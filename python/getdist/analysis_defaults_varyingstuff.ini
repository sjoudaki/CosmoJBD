#Confidence limits for marginalized constraints.
#Also used for 2D plots, but only number set by plot settings actually shown
contours = 0.68 0.95 0.997 0.99993666 0.999999426697

#If the distribution is skewed, so two probability of tails differs by more 
#than credible_interval_threshold of the peak value, use equal-probability limits 
#rather than integrating inwards equally at both tails.
#Note credible interval depends on density estimation parameters
credible_interval_threshold = 0.05

#Determine bounds from projected ND confidence range for contours[ND_contour_range]
#If -1 use bounds determined entirely from 1D marginalized densities
#Use 0 or 1 if 2D plot contours are hitting edges
range_ND_contour = -1

#1D marginalized confidence limit to use to determine parameter ranges
range_confidence = 0.001
#range_confidence = 0.0001

#Confidence limit to use for convergence tests (splits and Raftery Lewis)
converge_test_limit = 0.95

#Sample binning for 1D plots
#fine_bins = 1024
#fine_bins = 4096
fine_bins = 16384

#if -1: set optimized smoothing bandwidth automatically for each parameter
#if >= 1: smooth by smooth_scale_1D bin widths
#if > 0  and <1: smooth by Gaussian of smooth_scale_1D standard deviations in each parameter
#                (around 0.2-0.5 is often good)
#if < 0: automatic, with the overall smoothing length scaled by abs(smooth_scale_1D) from default
smooth_scale_1D =-1

#0 is basic normalization correction
#1 is linear boundary kernel (should get gradient correct)
#2 is a higher order kernel, that also affects estimates way from the boundary (1D only)
boundary_correction_order=1
#boundary_correction_order=2

#Correct for (over-smoothing) biases using multiplicative bias correction
#i.e. by interating estimates using the re-weighted 'flattened' bins
#Note that automatic bandwidth accounts for this by increasing the smoothing scale
#as mult_bias_correction_order increases (may not converge for large values).
mult_bias_correction_order = 1

#if -1: automatic optimized bandwidth matrix selection
#if >= 1: smooth by smooth_scale_2D bin widths
#if > 0  and <1: smooth by Gaussian of smooth_scale_2D standard deviations in each parameter
#                (around 0.3-0.7 is often good)
#if < 0: automatic, with the overall smoothing length scaled by abs(smooth_scale_2D) from default
smooth_scale_2D = -1
#smooth_scale_2D = 2

#maximum correlation ellipticity to allow for 2D kernels. Set to 0 to force non-elliptical.
max_corr_2D = 0.99
#max_corr_2D = 0.9999
#max_corr_2D = 0.49
#max_corr_2D = 0

#sample binning in each direction for 2D plotting
#fine_bins_2D = 256
#fine_bins_2D = 4096
#fine_bins_2D = 2048
fine_bins_2D = 1024

#maximum number of points for 3D plots
max_scatter_points = 2000

#output bins for 1D plotting (only for GetDist.py output to files, or scale if smooth_scale_2D>1) 
#num_bins = 100
num_bins = 400

#output bins for 2D plotting (not used, just scale if smooth_scale_2D>1) 
#num_bins_2D=40
num_bins_2D=100
#num_bins_2D=400
#num_bins_2D=4000

#For disgarding burn-in if using raw chains. Set to zero if already removed or you have independent samples.
#if < 1 interpreted as a fraction of the total number of rows (0.3 ignores first 30% of lines)
ignore_rows = 0.3
#ignore_rows = 0
